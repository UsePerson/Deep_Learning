{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "supported-origin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from activityFunction import ActivationFunction as AF\n",
    "from errorFunction import ErrorFunction as EF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "lesser-bosnia",
   "metadata": {},
   "outputs": [],
   "source": [
    "class nn:\n",
    "    \n",
    "    def __init__(self, af='Sigmoid', ef='cross_entropy', lr=0.5 ):\n",
    "        \n",
    "        self.af = AF(types=af)\n",
    "        self.ef = EF(types=ef)\n",
    "        self.lr = lr\n",
    "        self.layer_state = np.array([])\n",
    "    \n",
    "    def add_layer(self, input_size, neuron_size ):\n",
    "        \n",
    "        state = Layer_state(input_size, neuron_size, self.af)\n",
    "        self.layer_state = np.append(self.layer_state, state) \n",
    "        \n",
    "    def feedforward(self, inputs):\n",
    "        \n",
    "        print(inputs)\n",
    "        print(inputs.shape)\n",
    "        data = np.array(inputs[0, 0 : self.layer_state[0].inputs ])\n",
    "        for i, Layer in np.ndenumerate(self.layer_state):\n",
    "                \n",
    "            data = Layer.feed_forward(data)\n",
    "            \n",
    "        return data\n",
    "    \n",
    "    \n",
    "    def calculate_delta(self,output):\n",
    "        \n",
    "        # last delta = derivative error function * derivative activity function\n",
    "#         self.layer_state[-1].delta = self.af.dfunc(self.layer_state[-1].output) * self.ef.dfunc(output, self.layer_state[-1].output) \n",
    "        self.layer_state[-1].delta = self.layer_state[-1].output - output \n",
    "        i = np.size(self.layer_state) - 2 # sub 2, because have already calcutaled the last delta\n",
    "        \n",
    "        while i >= 0:\n",
    "            \n",
    "            # delta(i) = weight * delta(i+1) * derivative activity function\n",
    "#             self.layer_state[i].delta = self.layer_state[i+1].weight.T.dot( self.layer_state[i+1].delta ) * self.af.dfunc(self.layer_state[i].output)\n",
    "            self.layer_state[i].delta = self.layer_state[i + 1].weight.T.dot(self.layer_state[i+1].delta) * self.layer_state[i].output * (1 - self.layer_state[i].output)\n",
    "            i -= 1\n",
    "            \n",
    "    def update_weights(self, inputs):\n",
    "        \n",
    "        # update first weight and bias\n",
    "        ## weight = weight - learning * delta * input\n",
    "        ## bias = bias - learning rate * delta\n",
    "        self.layer_state[0].weight = self.layer_state[0].weight - self.lr * self.layer_state[0].delta.dot(inputs)\n",
    "        self.layer_state[0].bias = self.layer_state[0].bias - self.lr * self.layer_state[0].delta\n",
    "        \n",
    "        # update other weight and bias\n",
    "        ## weight(i) = weight - learning * delta(i) * input(i - 1)\n",
    "        ## bias(i) = bias - learning rate * delta(i) \n",
    "        i = 1    \n",
    "        while i < np.size(self.layer_state):\n",
    "            \n",
    "            self.layer_state[i].weight = self.layer_state[i].weight - self.lr * self.layer_state[i].delta.dot( self.layer_state[i-1].output.T)\n",
    "            self.layer_state[i].bias = self.layer_state[i].bias - self.lr * self.layer_state[i].delta\n",
    "            i += 1\n",
    "    \n",
    "    def backpropagation(self, dataset):\n",
    "        \n",
    "        output = np.array(dataset[0,self.layer_state[0].inputs:])\n",
    "        inputs = np.array(dataset[0,0:self.layer_state[0].inputs])\n",
    "\n",
    "        self.calculate_delta(output.T)\n",
    "        \n",
    "        self.update_weights(inputs)\n",
    "    \n",
    "    def train_accuracy(self, output, ans):\n",
    "        \n",
    "        if np.array_equal(np.where(output == output.max()), np.where(ans == ans.max())) :\n",
    "            \n",
    "            return 1\n",
    "        \n",
    "        return 0\n",
    "    \n",
    "    def train(self, inputs, validation_rate, epoch):\n",
    "        \n",
    "        train_size = int(np.size(inputs, 0) * (1 - validation_rate))\n",
    "        traininig_data =  np.array(inputs[ 0 : train_size ])\n",
    "        validation_data = np.array(inputs[ train_size :   ])\n",
    "        \n",
    "        for i in range(epoch):\n",
    "            \n",
    "            train_accurate_counter = 0\n",
    "            \n",
    "            for j in range(train_size):\n",
    "                \n",
    "                output = self.feedforward(traininig_data[ j ])\n",
    "                train_accurate_counter += self.train_accuracy(output, np.array(traininig_data[ j, self.layer_state[0].inputs : ]))\n",
    "                self.backpropagation(np.array(traininig_data[ j ]))\n",
    "                \n",
    "            print(\"i :\", i)\n",
    "            print(\"aauracy : \", train_accurate_counter / train_size )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "corporate-process",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer_state:\n",
    "    \n",
    "    def __init__(self, input_size, neuron_size, af):\n",
    "        \n",
    "        self.__neuron_size = neuron_size\n",
    "        self.__input_size = input_size\n",
    "        self.__weight = np.random.randn(neuron_size, input_size) \n",
    "        self.__bias = np.random.randn(neuron_size,1) \n",
    "        self.__af = af\n",
    "        self.__output = np.array([])\n",
    "        self.__delta = np.array([])\n",
    "        \n",
    "    @property\n",
    "    def delta(self):\n",
    "        \n",
    "        return self.__delta\n",
    "    \n",
    "    @delta.setter\n",
    "    def delta(self, delta):\n",
    "        \n",
    "        self.__delta = delta\n",
    "    \n",
    "    @property\n",
    "    def inputs(self):\n",
    "        \n",
    "        return self.__input_size\n",
    "    \n",
    "    @property\n",
    "    def neurons(self):\n",
    "        \n",
    "        return self.__neuron_size\n",
    "    \n",
    "    @property\n",
    "    def weight(self):\n",
    "        \n",
    "        return self.__weight\n",
    "    \n",
    "    @weight.setter\n",
    "    def weight(self, weight):\n",
    "        \n",
    "        self.__weight = weight\n",
    "    \n",
    "    @property\n",
    "    def bias(self):\n",
    "        \n",
    "        return self.__bias\n",
    "    \n",
    "    @bias.setter\n",
    "    def bias(self, bias):\n",
    "        \n",
    "        self.__bias = bias\n",
    "    \n",
    "    @property\n",
    "    def output(self):\n",
    "        \n",
    "        return self.__output\n",
    "    \n",
    "    @output.setter\n",
    "    def output(self, output):\n",
    "    \n",
    "        self.__output = output\n",
    "    \n",
    "    def feed_forward(self, inputs):\n",
    "        \n",
    "        n = self.weight.dot(inputs.T) + self.bias\n",
    "        self.output = self.__af.func(n)        \n",
    "        return self.__output.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "wanted-example",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data  = np.loadtxt('./train/train_img.txt', delimiter=',')\n",
    "train_label = np.loadtxt('./train/train_label.txt', delimiter=',')\n",
    "train_data  = np.array(train_data)\n",
    "train_label = pd.get_dummies(train_label)\n",
    "\n",
    "train = np.append(train_data, np.array(train_label), axis=1)\n",
    "np.random.shuffle(train)\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "accurate-dealer",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = nn(af='Sigmoid', ef='cross_entropy', lr=0.1)\n",
    "NN.add_layer(np.size(train_data, 1), 32)\n",
    "NN.add_layer(32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "harmful-shore",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   2.\n",
      " 101. 228. 255. 151.  24.   4.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  69.\n",
      " 253. 253. 253. 253. 253. 159.   2.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  32. 224.\n",
      " 253. 253. 253. 253. 253. 253.  24.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  24. 202.\n",
      " 253. 253. 194. 216. 253. 253.  24.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  63.\n",
      " 253. 192.  19. 163. 253. 253.  24.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  23.\n",
      "  93.  20.  12. 217. 253. 190.   9.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.  81. 253. 253. 154.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.  81. 253. 253. 154.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0. 109. 253. 253. 127.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.  55. 240. 253. 230.  23.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  19. 183. 253. 253.  66.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 105. 253. 253. 253.  37.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.  52.  81.  81.  81. 112.\n",
      " 242. 253. 253. 143.   7.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.  21. 211. 238. 253. 253. 253. 253.\n",
      " 253. 253. 186.   8.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0. 131. 253. 253. 253. 253. 253. 253.\n",
      " 253. 253. 242. 174.  14.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  17. 241. 253. 253. 253. 253. 253. 253.\n",
      " 253. 253. 253. 253. 182.  61.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0. 131. 253. 253. 253. 253. 253. 253. 253.\n",
      " 139.  24.  64. 236. 253. 244. 118.   8.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0. 143. 253. 253. 253. 253. 253. 253. 140.\n",
      "   5.   0.   0.  15. 165. 253. 253.  18.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  16. 205. 253. 253. 253. 253. 142.   3.\n",
      "   0.   0.   0.   0.   5.  12.  12.   1.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.  28. 253. 253. 171.  45.   2.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   1.]\n",
      "(787,)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-29807cd7c19b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-e06b412fe7ac>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, inputs, validation_rate, epoch)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraininig_data\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m                 \u001b[0mtrain_accurate_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraininig_data\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackpropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraininig_data\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-e06b412fe7ac>\u001b[0m in \u001b[0;36mfeedforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndenumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "NN.train(train, 0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-single",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-turkish",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-valve",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-midnight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-occasion",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
